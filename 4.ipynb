{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmSquJx836zN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "# Load the Fashion MNIST dataset\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "# Length of the training dataset\n",
        "train_length = len(X_train)\n",
        "print(\"Length of training dataset:\", train_length)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_length = len(X_test)\n",
        "\n",
        "print(\"Length of testing dataset:\", test_length)\n",
        "plt.figure(figsize=(10, 2))\n",
        "# Display some rows of the training dataset\n",
        "print(\"Training Dataset:\")\n",
        "for i in range(5):\n",
        " plt.subplot(1, 5, i+1)\n",
        " plt.imshow(X_train[i], cmap='gray')\n",
        " plt.title(f\"Label: {y_train[i]}\")\n",
        " plt.axis('off')\n",
        "plt.show()\n",
        "plt.figure(figsize=(10, 2))\n",
        "# Display some rows of the testing dataset\n",
        "print(\"Testing Dataset:\")\n",
        "for i in range(5):\n",
        " plt.subplot(1, 5, i+1)\n",
        " plt.imshow(X_test[i], cmap='gray')\n",
        " plt.title(f\"Label: {y_test[i]}\")\n",
        " plt.axis('off')\n",
        " plt.show()\n"
      ],
      "metadata": {
        "id": "deEBJL2r3-Nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values to the range [0, 1]\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "# Flatten the images (convert 28x28 images into 1D arrays)\n",
        "X_train_flat = X_train.reshape(-1, 28 * 28)\n",
        "X_test_flat = X_test.reshape(-1, 28 * 28)\n",
        "# Convert class vectors to binary class matrices (one-hot encoding)\n",
        "num_classes = 10\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "# Define callbacks for early stopping and model checkpointing\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3,\n",
        "restore_best_weights=True)\n",
        "model_checkpoint = keras.callbacks.ModelCheckpoint(\"best_model.h5\", monitor='val_loss',\n",
        "save_best_only=True)\n",
        "# Define the model with at least 2 hidden layers\n",
        "model = keras.Sequential([\n",
        " layers.Dense(128, activation='relu', input_shape=(28 * 28,)),\n",
        " layers.Dense(64, activation='relu'),\n",
        " layers.Dense(32, activation='relu'),\n",
        " layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        " loss='categorical_crossentropy',\n",
        " metrics=['accuracy'])\n",
        "# Train the model with callbacks\n",
        "history = model.fit(X_train_flat, y_train, epochs=20, batch_size=32,\n",
        " validation_split=0.2, callbacks=[early_stopping, model_checkpoint])\n"
      ],
      "metadata": {
        "id": "J6ag8Bx94KFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test_flat, y_test)\n",
        "print('Test accuracy:', test_acc)\n",
        "# Plot training history\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eoFsdrP94Ono"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}